{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contando N-Gramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "sents = list(gutenberg.sents('austen-emma.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero vemos cómo imprimir todos los trigramas de una sola oración:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'Emma', 'by']\n",
      "['Emma', 'by', 'Jane']\n",
      "['by', 'Jane', 'Austen']\n",
      "['Jane', 'Austen', '1816']\n",
      "['Austen', '1816', ']']\n"
     ]
    }
   ],
   "source": [
    "sent = sents[0]\n",
    "\n",
    "n = 3  # trigramas\n",
    "for i in range(len(sent) - n + 1):\n",
    "    print(sent[i:i+n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora veamos cómo contar los trigramas de todas las oraciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "count = defaultdict(int)\n",
    "\n",
    "for sent in sents:\n",
    "    for i in range(len(sent) - n + 1):\n",
    "        ngram = tuple(sent[i:i+n])  # los diccionarios no pueden guardar listas, pero sí tuplas\n",
    "        count[ngram] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Hay', 'que', 'dejar', 'de', 'robar', 'por', 'dos', 'años', '.'],\n",
       " ['Estamos', 'bien', 'los', '33']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "\n",
    "def split_and_tokenize(text):\n",
    "    tokens = []\n",
    "    for sent in sent_tokenize(text):\n",
    "        tokens.append(word_tokenize(sent))\n",
    "    return tokens\n",
    "\n",
    "\n",
    "split_and_tokenize(\"Hay que dejar de robar por dos años. Estamos bien los 33\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<s>', 'Sí'],\n",
       " ['Sí', 'se'],\n",
       " ['se', 'puede'],\n",
       " ['puede', '!'],\n",
       " ['<s>', 'Sí'],\n",
       " ['Sí', 'se'],\n",
       " ['se', 'puede'],\n",
       " ['puede', '!']]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _generate_n_grams_for_sentence(sentence, n):\n",
    "    ngrams = []\n",
    "    \n",
    "    \"\"\"\n",
    "    Los n-1 primeros tokens tengo que rellenarlos \n",
    "    \"\"\"\n",
    "    for i in range(min(n-1, len(sentence))):\n",
    "        ngram = ['<s>'] * (n-(i+1)) + sentence[0:i+1]\n",
    "        ngrams.append(ngram)\n",
    "        \n",
    "    for i in range(n-2, len(sentence)-n+1):\n",
    "        ngrams.append(sentence[i:i+n])\n",
    "    \n",
    "    return ngrams\n",
    "        \n",
    "def generate_ngrams(sents, n):\n",
    "    \"\"\"\n",
    "    Generar n-gramas a partir de las sentencias\n",
    "    \"\"\"\n",
    "    ngrams = []\n",
    "    \n",
    "    for sent in sents:\n",
    "        ngrams += _generate_n_grams_for_sentence(sent, n)\n",
    "    return ngrams\n",
    "\n",
    "texto = \"Sí se puede! Sí se puede!\"\n",
    "sents = split_and_tokenize(texto)\n",
    "#['<s>'] * 10\n",
    "generate_ngrams(sents, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<s>', '<s>', 'El'],\n",
       " ['<s>', 'El', 'Bajo'],\n",
       " ['Bajo', 'porteño', 'ha'],\n",
       " ['porteño', 'ha', 'sido'],\n",
       " ['ha', 'sido', 'protagonista'],\n",
       " ['sido', 'protagonista', 'de'],\n",
       " ['protagonista', 'de', 'constantes'],\n",
       " ['de', 'constantes', 'cambios'],\n",
       " ['constantes', 'cambios', 'a'],\n",
       " ['cambios', 'a', 'lo'],\n",
       " ['a', 'lo', 'largo'],\n",
       " ['lo', 'largo', 'de'],\n",
       " ['largo', 'de', 'la'],\n",
       " ['de', 'la', 'historia'],\n",
       " ['la', 'historia', 'y'],\n",
       " ['historia', 'y', 'parece'],\n",
       " ['y', 'parece', 'que'],\n",
       " ['parece', 'que', 'en'],\n",
       " ['que', 'en', 'los'],\n",
       " ['en', 'los', 'próximos'],\n",
       " ['los', 'próximos', 'años'],\n",
       " ['próximos', 'años', 'las'],\n",
       " ['años', 'las', 'obras'],\n",
       " ['las', 'obras', 'continuarán'],\n",
       " ['obras', 'continuarán', '.'],\n",
       " ['<s>', '<s>', 'Polémicos'],\n",
       " ['<s>', 'Polémicos', 'traslados'],\n",
       " ['traslados', 'de', 'estatuas'],\n",
       " ['de', 'estatuas', ','],\n",
       " ['estatuas', ',', 'reacomodo'],\n",
       " [',', 'reacomodo', 'de'],\n",
       " ['reacomodo', 'de', 'calles'],\n",
       " ['de', 'calles', ','],\n",
       " ['calles', ',', 'estacionamientos'],\n",
       " [',', 'estacionamientos', ','],\n",
       " ['estacionamientos', ',', 'nuevos'],\n",
       " [',', 'nuevos', 'edificios'],\n",
       " ['nuevos', 'edificios', 'y'],\n",
       " ['edificios', 'y', 'enrejado'],\n",
       " ['y', 'enrejado', 'son'],\n",
       " ['enrejado', 'son', 'algunas'],\n",
       " ['son', 'algunas', 'de'],\n",
       " ['algunas', 'de', 'las'],\n",
       " ['de', 'las', 'modificaciones'],\n",
       " ['las', 'modificaciones', 'que'],\n",
       " ['modificaciones', 'que', 'realizaron'],\n",
       " ['que', 'realizaron', 'los'],\n",
       " ['realizaron', 'los', 'distintos'],\n",
       " ['los', 'distintos', 'gobiernos'],\n",
       " ['distintos', 'gobiernos', 'desde'],\n",
       " ['gobiernos', 'desde', '1937'],\n",
       " ['desde', '1937', ','],\n",
       " ['1937', ',', 'cuando'],\n",
       " [',', 'cuando', 'toda'],\n",
       " ['cuando', 'toda', 'el'],\n",
       " ['toda', 'el', 'área'],\n",
       " ['el', 'área', 'era'],\n",
       " ['área', 'era', 'de'],\n",
       " ['era', 'de', 'acceso'],\n",
       " ['de', 'acceso', 'público'],\n",
       " ['acceso', 'público', '.']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto = \"El Bajo porteño ha sido protagonista de constantes cambios a lo largo de la historia\\\n",
    " y parece que en los próximos años las obras continuarán. Polémicos traslados de estatuas, reacomodo\\\n",
    " de calles, estacionamientos, nuevos edificios y enrejado son algunas de las modificaciones que realizaron\\\n",
    " los distintos gobiernos desde 1937, cuando toda el área era de acceso público.\"\n",
    "\n",
    "sents = split_and_tokenize(texto)\n",
    "generate_n_grams(sents, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código sirve para n-gramas en general.\n",
    "\n",
    "Tareas pendientes:\n",
    "- Agregar marcadores de principio y final de oración\n",
    "- Contar n-gramas y (n-1)-gramas al mismo tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generando Lenguaje Natural\n",
    "\n",
    "El siguiente modelo de bigramas se aprende a partir de dos oraciones:\n",
    "- \"el gato come pescado\"\n",
    "- \"la gata come salmón\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('la', 0.5), ('el', 0.5)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = {\n",
    "    '<s>': {'el': 0.5, 'la': 0.5},\n",
    "    # '<s>': {'el': 0.6, 'la': 0.2, 'los': 0.1, 'las': 0.1},\n",
    "    'el': {'gato': 1.0},\n",
    "    'gato': {'come': 1.0},\n",
    "    'come': {'pescado': 0.5, 'salmón': 0.5},\n",
    "    'pescado': {'.': 1.0},\n",
    "    '.': {'</s>': 1.0},\n",
    "    'la': {'gata': 1.0},\n",
    "    'gata': {'come': 1.0},\n",
    "    'salmón': {'.': 1.0},\n",
    "}\n",
    "\n",
    "list(probs['<s>'].items())  # convertir un diccionario a lista de pares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada entrada del diccionario contiene una distribución discreta finita para la palabra siguiente dada la palabra anterior. Samplear de una distribución discreta finita es tan fácil como samplear un número al azar entre 0 y 1 y ver en qué región cae (ver [Wikipedia](https://en.wikipedia.org/wiki/Pseudo-random_number_sampling#Finite_discrete_distributions)).\n",
    "\n",
    "Empezamos sampleando la primer palabra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'la'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import random\n",
    "\n",
    "def sample(problist):\n",
    "    r = random()  # entre 0 y 1\n",
    "    i = 0\n",
    "    word, prob = problist[0]\n",
    "    acum = prob\n",
    "    while r > acum:\n",
    "        i += 1\n",
    "        word, prob = problist[i]\n",
    "        acum += prob\n",
    "    \n",
    "    return word\n",
    "\n",
    "sample(list(probs['<s>'].items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que el resultado del sampleo se corresponde con las probabilidades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'el': 505, 'la': 495})\n"
     ]
    }
   ],
   "source": [
    "results = [sample(list(probs['<s>'].items())) for i in range(1000)]\n",
    "\n",
    "from collections import Counter\n",
    "print(Counter(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones:**\n",
    "- Si se ordena la lista de probabilidades de mayor a menor, el sampling es más rápido.\n",
    "- El sampling también se puede hacer usando [random.choices](https://docs.python.org/3/library/random.html#random.choices) de python\n",
    "ó [random.choice](https://stackoverflow.com/questions/11373192/generating-discrete-random-variables-with-specified-weights-using-scipy-or-numpy) de numpy.\n",
    "\n",
    "Ahora veamos cómo samplear una oración completa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la\n",
      "gata\n",
      "come\n",
      "pescado\n",
      ".\n",
      "</s>\n"
     ]
    }
   ],
   "source": [
    "word = '<s>'\n",
    "while word != '</s>':\n",
    "    problist = list(probs[word].items())\n",
    "    word = sample(problist)\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acá se ve que se pueden generar oraciones nuevas (no vistas en tiempo de entrenamiento).\n",
    "\n",
    "Tareas pendientes:\n",
    "- adaptar el código a n-gramas en general: usar tuplas como claves en probs!\n",
    "- precalcular las listas ordenadas de mayor a menor (ver sorted_prob en los tests)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
