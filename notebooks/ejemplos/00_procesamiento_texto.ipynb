{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK\n",
    "\n",
    "Descargar corpus y modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()\n",
    "# instalar corpus gutenberg y modelo punkt (tokenizador y segmentador)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jmperez/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /home/jmperez/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']'], ['VOLUME', 'I'], ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg.sents('austen-emma.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estadísticas Básicas\n",
    "\n",
    "Versión básica con diccionarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[': 2,\n",
       " 'Emma': 865,\n",
       " 'by': 558,\n",
       " 'Jane': 301,\n",
       " 'Austen': 1,\n",
       " '1816': 1,\n",
       " ']': 1,\n",
       " 'VOLUME': 3,\n",
       " 'I': 3178,\n",
       " 'CHAPTER': 55,\n",
       " 'Woodhouse': 313,\n",
       " ',': 11454,\n",
       " 'handsome': 37,\n",
       " 'clever': 27,\n",
       " 'and': 4672,\n",
       " 'rich': 14,\n",
       " 'with': 1187,\n",
       " 'a': 3004,\n",
       " 'comfortable': 34,\n",
       " 'home': 130,\n",
       " 'happy': 122,\n",
       " 'disposition': 24,\n",
       " 'seemed': 141,\n",
       " 'to': 5183,\n",
       " 'unite': 3,\n",
       " 'some': 248,\n",
       " 'of': 4279,\n",
       " 'the': 4844,\n",
       " 'best': 85,\n",
       " 'blessings': 6,\n",
       " 'existence': 8,\n",
       " ';': 2199,\n",
       " 'had': 1606,\n",
       " 'lived': 25,\n",
       " 'nearly': 14,\n",
       " 'twenty': 30,\n",
       " '-': 574,\n",
       " 'one': 413,\n",
       " 'years': 57,\n",
       " 'in': 2118,\n",
       " 'world': 81,\n",
       " 'very': 1151,\n",
       " 'little': 354,\n",
       " 'distress': 19,\n",
       " 'or': 490,\n",
       " 'vex': 1,\n",
       " 'her': 2381,\n",
       " '.': 6928,\n",
       " 'She': 562,\n",
       " 'was': 2385,\n",
       " 'youngest': 4,\n",
       " 'two': 171,\n",
       " 'daughters': 7,\n",
       " 'most': 243,\n",
       " 'affectionate': 9,\n",
       " 'indulgent': 2,\n",
       " 'father': 207,\n",
       " 'consequence': 27,\n",
       " 'sister': 33,\n",
       " \"'\": 1007,\n",
       " 's': 933,\n",
       " 'marriage': 34,\n",
       " 'been': 759,\n",
       " 'mistress': 11,\n",
       " 'his': 1088,\n",
       " 'house': 95,\n",
       " 'from': 535,\n",
       " 'early': 40,\n",
       " 'period': 18,\n",
       " 'Her': 88,\n",
       " 'mother': 72,\n",
       " 'died': 4,\n",
       " 'too': 253,\n",
       " 'long': 144,\n",
       " 'ago': 32,\n",
       " 'for': 1321,\n",
       " 'have': 1301,\n",
       " 'more': 464,\n",
       " 'than': 415,\n",
       " 'an': 452,\n",
       " 'indistinct': 1,\n",
       " 'remembrance': 8,\n",
       " 'caresses': 1,\n",
       " 'place': 92,\n",
       " 'supplied': 5,\n",
       " 'excellent': 33,\n",
       " 'woman': 129,\n",
       " 'as': 1387,\n",
       " 'governess': 9,\n",
       " 'who': 281,\n",
       " 'fallen': 7,\n",
       " 'short': 67,\n",
       " 'affection': 50,\n",
       " 'Sixteen': 2,\n",
       " 'Miss': 592,\n",
       " 'Taylor': 48,\n",
       " 'Mr': 1153,\n",
       " 'family': 77,\n",
       " 'less': 68,\n",
       " 'friend': 177,\n",
       " 'fond': 39,\n",
       " 'both': 83,\n",
       " 'but': 1148,\n",
       " 'particularly': 46,\n",
       " 'Between': 2,\n",
       " '_them_': 4,\n",
       " 'it': 2128,\n",
       " 'intimacy': 20,\n",
       " 'sisters': 12,\n",
       " 'Even': 10,\n",
       " 'before': 243,\n",
       " 'ceased': 6,\n",
       " 'hold': 14,\n",
       " 'nominal': 1,\n",
       " 'office': 16,\n",
       " 'mildness': 1,\n",
       " 'temper': 36,\n",
       " 'hardly': 71,\n",
       " 'allowed': 40,\n",
       " 'impose': 1,\n",
       " 'any': 651,\n",
       " 'restraint': 3,\n",
       " 'shadow': 2,\n",
       " 'authority': 6,\n",
       " 'being': 356,\n",
       " 'now': 273,\n",
       " 'passed': 55,\n",
       " 'away': 138,\n",
       " 'they': 392,\n",
       " 'living': 17,\n",
       " 'together': 81,\n",
       " 'mutually': 3,\n",
       " 'attached': 25,\n",
       " 'doing': 45,\n",
       " 'just': 159,\n",
       " 'what': 434,\n",
       " 'she': 1778,\n",
       " 'liked': 16,\n",
       " 'highly': 24,\n",
       " 'esteeming': 1,\n",
       " 'judgment': 29,\n",
       " 'directed': 6,\n",
       " 'chiefly': 7,\n",
       " 'own': 301,\n",
       " 'The': 357,\n",
       " 'real': 41,\n",
       " 'evils': 10,\n",
       " 'indeed': 181,\n",
       " 'situation': 64,\n",
       " 'were': 591,\n",
       " 'power': 41,\n",
       " 'having': 145,\n",
       " 'rather': 145,\n",
       " 'much': 478,\n",
       " 'way': 155,\n",
       " 'think': 380,\n",
       " 'well': 315,\n",
       " 'herself': 279,\n",
       " 'these': 48,\n",
       " 'disadvantages': 1,\n",
       " 'which': 552,\n",
       " 'threatened': 4,\n",
       " 'alloy': 3,\n",
       " 'many': 133,\n",
       " 'enjoyments': 3,\n",
       " 'danger': 31,\n",
       " 'however': 114,\n",
       " 'at': 997,\n",
       " 'present': 89,\n",
       " 'so': 924,\n",
       " 'unperceived': 2,\n",
       " 'that': 1730,\n",
       " 'did': 335,\n",
       " 'not': 2101,\n",
       " 'means': 48,\n",
       " 'rank': 9,\n",
       " 'misfortunes': 1,\n",
       " 'Sorrow': 1,\n",
       " 'came': 119,\n",
       " '--': 1437,\n",
       " 'gentle': 16,\n",
       " 'sorrow': 3,\n",
       " 'all': 835,\n",
       " 'shape': 5,\n",
       " 'disagreeable': 20,\n",
       " 'consciousness': 21,\n",
       " '.--': 685,\n",
       " 'married': 44,\n",
       " 'It': 400,\n",
       " 'loss': 23,\n",
       " 'first': 209,\n",
       " 'brought': 54,\n",
       " 'grief': 5,\n",
       " 'on': 677,\n",
       " 'wedding': 17,\n",
       " 'day': 190,\n",
       " 'this': 418,\n",
       " 'beloved': 9,\n",
       " 'sat': 37,\n",
       " 'mournful': 1,\n",
       " 'thought': 226,\n",
       " 'continuance': 2,\n",
       " 'over': 139,\n",
       " 'bride': 13,\n",
       " 'people': 93,\n",
       " 'gone': 79,\n",
       " 'left': 68,\n",
       " 'dine': 15,\n",
       " 'no': 616,\n",
       " 'prospect': 13,\n",
       " 'third': 5,\n",
       " 'cheer': 4,\n",
       " 'evening': 96,\n",
       " 'composed': 6,\n",
       " 'himself': 146,\n",
       " 'sleep': 2,\n",
       " 'after': 140,\n",
       " 'dinner': 47,\n",
       " 'usual': 51,\n",
       " 'then': 150,\n",
       " 'only': 327,\n",
       " 'sit': 38,\n",
       " 'lost': 21,\n",
       " 'event': 24,\n",
       " 'every': 398,\n",
       " 'promise': 21,\n",
       " 'happiness': 76,\n",
       " 'Weston': 439,\n",
       " 'man': 233,\n",
       " 'unexceptionable': 7,\n",
       " 'character': 43,\n",
       " 'easy': 28,\n",
       " 'fortune': 38,\n",
       " 'suitable': 4,\n",
       " 'age': 22,\n",
       " 'pleasant': 39,\n",
       " 'manners': 52,\n",
       " 'there': 420,\n",
       " 'satisfaction': 28,\n",
       " 'considering': 17,\n",
       " 'self': 23,\n",
       " 'denying': 7,\n",
       " 'generous': 4,\n",
       " 'friendship': 26,\n",
       " 'always': 235,\n",
       " 'wished': 48,\n",
       " 'promoted': 4,\n",
       " 'match': 32,\n",
       " 'black': 5,\n",
       " 'morning': 110,\n",
       " 'work': 22,\n",
       " 'want': 89,\n",
       " 'would': 815,\n",
       " 'be': 1970,\n",
       " 'felt': 113,\n",
       " 'hour': 83,\n",
       " 'recalled': 2,\n",
       " 'past': 20,\n",
       " 'kindness': 40,\n",
       " 'sixteen': 7,\n",
       " 'how': 263,\n",
       " 'taught': 7,\n",
       " 'played': 8,\n",
       " 'five': 41,\n",
       " 'old': 85,\n",
       " 'devoted': 5,\n",
       " 'powers': 14,\n",
       " 'attach': 5,\n",
       " 'amuse': 8,\n",
       " 'health': 39,\n",
       " 'nursed': 3,\n",
       " 'through': 61,\n",
       " 'various': 6,\n",
       " 'illnesses': 3,\n",
       " 'childhood': 2,\n",
       " 'A': 125,\n",
       " 'large': 35,\n",
       " 'debt': 1,\n",
       " 'gratitude': 29,\n",
       " 'owing': 3,\n",
       " 'here': 133,\n",
       " 'intercourse': 12,\n",
       " 'last': 119,\n",
       " 'seven': 7,\n",
       " 'equal': 57,\n",
       " 'footing': 3,\n",
       " 'perfect': 33,\n",
       " 'unreserve': 6,\n",
       " 'soon': 221,\n",
       " 'followed': 29,\n",
       " 'Isabella': 69,\n",
       " 'their': 297,\n",
       " 'each': 46,\n",
       " 'other': 220,\n",
       " 'yet': 106,\n",
       " 'dearer': 5,\n",
       " 'tenderer': 1,\n",
       " 'recollection': 8,\n",
       " 'companion': 27,\n",
       " 'such': 440,\n",
       " 'few': 106,\n",
       " 'possessed': 3,\n",
       " ':': 133,\n",
       " 'intelligent': 4,\n",
       " 'informed': 5,\n",
       " 'useful': 21,\n",
       " 'knowing': 26,\n",
       " 'ways': 16,\n",
       " 'interested': 15,\n",
       " 'its': 118,\n",
       " 'concerns': 9,\n",
       " 'peculiarly': 10,\n",
       " 'pleasure': 114,\n",
       " 'scheme': 23,\n",
       " 'hers': 20,\n",
       " 'whom': 71,\n",
       " 'could': 825,\n",
       " 'speak': 99,\n",
       " 'arose': 4,\n",
       " 'never': 347,\n",
       " 'find': 74,\n",
       " 'fault': 20,\n",
       " 'How': 108,\n",
       " 'bear': 51,\n",
       " 'change': 61,\n",
       " '?--': 200,\n",
       " 'true': 60,\n",
       " 'going': 118,\n",
       " 'half': 116,\n",
       " 'mile': 11,\n",
       " 'them': 432,\n",
       " 'aware': 26,\n",
       " 'great': 263,\n",
       " 'must': 564,\n",
       " 'difference': 30,\n",
       " 'between': 71,\n",
       " 'Mrs': 699,\n",
       " 'advantages': 12,\n",
       " 'natural': 51,\n",
       " 'domestic': 7,\n",
       " 'suffering': 16,\n",
       " 'intellectual': 3,\n",
       " 'solitude': 3,\n",
       " 'dearly': 2,\n",
       " 'loved': 27,\n",
       " 'he': 1365,\n",
       " 'He': 441,\n",
       " 'meet': 32,\n",
       " 'conversation': 42,\n",
       " 'rational': 18,\n",
       " 'playful': 2,\n",
       " 'evil': 33,\n",
       " 'actual': 3,\n",
       " 'disparity': 7,\n",
       " 'ages': 2,\n",
       " '(': 88,\n",
       " ')': 40,\n",
       " 'increased': 12,\n",
       " 'constitution': 7,\n",
       " 'habits': 12,\n",
       " 'valetudinarian': 1,\n",
       " 'life': 80,\n",
       " 'without': 211,\n",
       " 'activity': 4,\n",
       " 'mind': 128,\n",
       " 'body': 193,\n",
       " 'older': 8,\n",
       " 'though': 169,\n",
       " 'everywhere': 3,\n",
       " 'friendliness': 3,\n",
       " 'heart': 66,\n",
       " 'amiable': 34,\n",
       " 'talents': 8,\n",
       " 'recommended': 9,\n",
       " 'him': 758,\n",
       " 'time': 272,\n",
       " 'comparatively': 2,\n",
       " 'removed': 10,\n",
       " 'matrimony': 7,\n",
       " 'settled': 39,\n",
       " 'London': 45,\n",
       " 'miles': 17,\n",
       " 'off': 99,\n",
       " 'beyond': 52,\n",
       " 'daily': 10,\n",
       " 'reach': 7,\n",
       " 'October': 4,\n",
       " 'November': 5,\n",
       " 'struggled': 2,\n",
       " 'Hartfield': 160,\n",
       " 'Christmas': 11,\n",
       " 'next': 63,\n",
       " 'visit': 86,\n",
       " 'husband': 34,\n",
       " 'children': 59,\n",
       " 'fill': 2,\n",
       " 'give': 157,\n",
       " 'society': 48,\n",
       " 'again': 219,\n",
       " 'Highbury': 125,\n",
       " 'populous': 2,\n",
       " 'village': 2,\n",
       " 'almost': 87,\n",
       " 'amounting': 1,\n",
       " 'town': 23,\n",
       " 'spite': 24,\n",
       " 'separate': 12,\n",
       " 'lawn': 4,\n",
       " 'shrubberies': 2,\n",
       " 'name': 55,\n",
       " 'really': 153,\n",
       " 'belong': 15,\n",
       " 'afforded': 8,\n",
       " 'equals': 1,\n",
       " 'Woodhouses': 4,\n",
       " 'All': 10,\n",
       " 'looked': 91,\n",
       " 'up': 190,\n",
       " 'acquaintance': 63,\n",
       " 'universally': 4,\n",
       " 'civil': 13,\n",
       " 'among': 51,\n",
       " 'accepted': 10,\n",
       " 'lieu': 1,\n",
       " 'even': 122,\n",
       " 'melancholy': 12,\n",
       " 'sigh': 19,\n",
       " 'wish': 134,\n",
       " 'impossible': 38,\n",
       " 'things': 60,\n",
       " 'till': 95,\n",
       " 'awoke': 1,\n",
       " 'made': 199,\n",
       " 'necessary': 36,\n",
       " 'cheerful': 29,\n",
       " 'His': 57,\n",
       " 'spirits': 64,\n",
       " 'required': 14,\n",
       " 'support': 8,\n",
       " 'nervous': 11,\n",
       " 'easily': 14,\n",
       " 'depressed': 6,\n",
       " 'used': 49,\n",
       " 'hating': 2,\n",
       " 'part': 66,\n",
       " 'kind': 82,\n",
       " 'Matrimony': 1,\n",
       " 'origin': 4,\n",
       " 'reconciled': 8,\n",
       " 'daughter': 62,\n",
       " 'marrying': 26,\n",
       " 'nor': 63,\n",
       " 'ever': 189,\n",
       " 'compassion': 13,\n",
       " 'entirely': 39,\n",
       " 'when': 312,\n",
       " 'obliged': 76,\n",
       " 'selfishness': 4,\n",
       " 'able': 72,\n",
       " 'suppose': 80,\n",
       " 'feel': 95,\n",
       " 'differently': 11,\n",
       " 'disposed': 21,\n",
       " 'done': 142,\n",
       " 'sad': 25,\n",
       " 'thing': 398,\n",
       " 'deal': 92,\n",
       " 'happier': 10,\n",
       " 'if': 375,\n",
       " 'spent': 21,\n",
       " 'rest': 50,\n",
       " 'smiled': 17,\n",
       " 'chatted': 1,\n",
       " 'cheerfully': 8,\n",
       " 'keep': 32,\n",
       " 'thoughts': 38,\n",
       " 'tea': 24,\n",
       " 'say': 308,\n",
       " 'exactly': 51,\n",
       " 'said': 484,\n",
       " '\"': 2004,\n",
       " 'Poor': 30,\n",
       " '!--': 338,\n",
       " 'What': 102,\n",
       " 'pity': 26,\n",
       " 'is': 1220,\n",
       " '!\"': 160,\n",
       " 'cannot': 138,\n",
       " 'agree': 15,\n",
       " 'you': 1677,\n",
       " 'papa': 30,\n",
       " 'know': 337,\n",
       " 'good': 340,\n",
       " 'humoured': 6,\n",
       " 'thoroughly': 19,\n",
       " 'deserves': 6,\n",
       " 'wife': 68,\n",
       " ';--': 124,\n",
       " 'live': 17,\n",
       " 'us': 145,\n",
       " 'my': 619,\n",
       " 'odd': 26,\n",
       " 'humours': 2,\n",
       " 'might': 322,\n",
       " '?\"': 238,\n",
       " 'But': 293,\n",
       " 'where': 71,\n",
       " 'advantage': 27,\n",
       " '?': 174,\n",
       " 'This': 108,\n",
       " 'three': 68,\n",
       " 'times': 28,\n",
       " 'And': 224,\n",
       " 'dear': 217,\n",
       " '.\"': 1157,\n",
       " 'often': 90,\n",
       " 'we': 260,\n",
       " 'shall': 212,\n",
       " 'see': 220,\n",
       " 'coming': 89,\n",
       " 'We': 89,\n",
       " 'meeting': 39,\n",
       " '!': 549,\n",
       " '_We_': 2,\n",
       " 'begin': 31,\n",
       " 'go': 129,\n",
       " 'pay': 25,\n",
       " 'My': 108,\n",
       " 'am': 422,\n",
       " 'get': 67,\n",
       " 'far': 70,\n",
       " 'Randalls': 90,\n",
       " 'distance': 25,\n",
       " 'walk': 55,\n",
       " 'No': 126,\n",
       " 'nobody': 54,\n",
       " 'your': 337,\n",
       " 'walking': 45,\n",
       " 'carriage': 69,\n",
       " 'sure': 204,\n",
       " 'James': 19,\n",
       " 'will': 559,\n",
       " 'like': 199,\n",
       " 'put': 63,\n",
       " 'horses': 25,\n",
       " 'are': 447,\n",
       " 'poor': 106,\n",
       " 'while': 113,\n",
       " 'paying': 11,\n",
       " 'our': 89,\n",
       " 'They': 148,\n",
       " 'into': 163,\n",
       " 'stable': 2,\n",
       " 'You': 303,\n",
       " 'already': 45,\n",
       " 'talked': 66,\n",
       " 'night': 41,\n",
       " 'may': 213,\n",
       " 'because': 53,\n",
       " 'housemaid': 1,\n",
       " 'doubt': 98,\n",
       " 'whether': 61,\n",
       " 'take': 116,\n",
       " 'anywhere': 15,\n",
       " 'else': 80,\n",
       " 'That': 76,\n",
       " 'got': 36,\n",
       " 'Hannah': 2,\n",
       " 'Nobody': 19,\n",
       " 'mentioned': 26,\n",
       " 'glad': 50,\n",
       " 'lucky': 10,\n",
       " 'slighted': 6,\n",
       " 'upon': 133,\n",
       " 'account': 59,\n",
       " 'make': 152,\n",
       " 'servant': 6,\n",
       " 'pretty': 66,\n",
       " 'spoken': 31,\n",
       " 'girl': 47,\n",
       " 'opinion': 71,\n",
       " 'Whenever': 6,\n",
       " 'curtseys': 1,\n",
       " 'asks': 3,\n",
       " 'me': 564,\n",
       " 'do': 580,\n",
       " 'manner': 75,\n",
       " 'needlework': 1,\n",
       " 'observe': 21,\n",
       " 'turns': 9,\n",
       " 'lock': 1,\n",
       " 'door': 47,\n",
       " 'right': 92,\n",
       " 'bangs': 1,\n",
       " 'comfort': 65,\n",
       " 'somebody': 11,\n",
       " 'about': 246,\n",
       " 'goes': 6,\n",
       " 'hearing': 32,\n",
       " 'tell': 73,\n",
       " 'spared': 7,\n",
       " 'exertions': 6,\n",
       " 'maintain': 4,\n",
       " 'flow': 6,\n",
       " 'ideas': 16,\n",
       " 'hoped': 43,\n",
       " 'help': 39,\n",
       " 'backgammon': 3,\n",
       " 'tolerably': 15,\n",
       " 'attacked': 2,\n",
       " 'regrets': 6,\n",
       " 'table': 27,\n",
       " 'placed': 15,\n",
       " 'visitor': 9,\n",
       " 'immediately': 69,\n",
       " 'afterwards': 41,\n",
       " 'walked': 52,\n",
       " 'unnecessary': 8,\n",
       " 'Knightley': 389,\n",
       " 'sensible': 25,\n",
       " 'eight': 7,\n",
       " 'thirty': 5,\n",
       " 'intimate': 10,\n",
       " 'connected': 11,\n",
       " 'elder': 4,\n",
       " 'brother': 54,\n",
       " 'frequent': 8,\n",
       " 'welcome': 16,\n",
       " 'directly': 51,\n",
       " 'mutual': 5,\n",
       " 'connexions': 10,\n",
       " 'returned': 39,\n",
       " 'late': 26,\n",
       " 'days': 50,\n",
       " 'absence': 14,\n",
       " 'Brunswick': 11,\n",
       " 'Square': 11,\n",
       " 'circumstance': 34,\n",
       " 'animated': 5,\n",
       " 'inquiries': 10,\n",
       " 'answered': 22,\n",
       " 'satisfactorily': 2,\n",
       " 'When': 51,\n",
       " 'gratefully': 5,\n",
       " 'observed': 22,\n",
       " 'come': 159,\n",
       " 'out': 212,\n",
       " 'call': 41,\n",
       " 'afraid': 65,\n",
       " 'shocking': 5,\n",
       " 'Not': 39,\n",
       " 'sir': 63,\n",
       " 'beautiful': 23,\n",
       " 'moonlight': 2,\n",
       " 'mild': 4,\n",
       " 'draw': 10,\n",
       " 'back': 67,\n",
       " 'fire': 16,\n",
       " 'found': 92,\n",
       " 'damp': 6,\n",
       " 'dirty': 5,\n",
       " 'catch': 14,\n",
       " 'cold': 54,\n",
       " 'Dirty': 1,\n",
       " 'Look': 5,\n",
       " 'shoes': 4,\n",
       " 'speck': 1,\n",
       " 'Well': 86,\n",
       " 'quite': 269,\n",
       " 'surprising': 2,\n",
       " 'vast': 6,\n",
       " 'rain': 22,\n",
       " 'rained': 1,\n",
       " 'dreadfully': 8,\n",
       " 'hard': 12,\n",
       " 'breakfast': 12,\n",
       " 'wanted': 75,\n",
       " 'By': 13,\n",
       " 'bye': 12,\n",
       " 'joy': 18,\n",
       " 'Being': 2,\n",
       " 'sort': 112,\n",
       " 'feeling': 56,\n",
       " 'hurry': 24,\n",
       " 'congratulations': 7,\n",
       " 'hope': 143,\n",
       " 'went': 46,\n",
       " 'behave': 3,\n",
       " 'Who': 13,\n",
       " 'cried': 81,\n",
       " 'Ah': 46,\n",
       " 'Tis': 2,\n",
       " 'business': 54,\n",
       " 'please': 35,\n",
       " 'possibly': 17,\n",
       " '`': 97,\n",
       " \".'\": 32,\n",
       " 'regard': 43,\n",
       " 'comes': 24,\n",
       " 'question': 39,\n",
       " 'dependence': 11,\n",
       " 'independence': 11,\n",
       " 'At': 34,\n",
       " 'rate': 18,\n",
       " 'better': 166,\n",
       " 'Especially': 1,\n",
       " '_one_': 6,\n",
       " 'those': 87,\n",
       " 'fanciful': 3,\n",
       " 'troublesome': 9,\n",
       " 'creature': 39,\n",
       " 'playfully': 2,\n",
       " 'head': 40,\n",
       " 'certainly': 90,\n",
       " 'believe': 101,\n",
       " ',\"': 421,\n",
       " 'sometimes': 37,\n",
       " 'dearest': 20,\n",
       " 'mean': 59,\n",
       " '_you_': 15,\n",
       " 'horrible': 5,\n",
       " 'idea': 100,\n",
       " 'Oh': 185,\n",
       " 'meant': 43,\n",
       " 'myself': 102,\n",
       " 'loves': 9,\n",
       " 'joke': 6,\n",
       " 'another': 106,\n",
       " 'fact': 24,\n",
       " 'faults': 11,\n",
       " 'told': 78,\n",
       " 'agreeable': 50,\n",
       " 'knew': 88,\n",
       " 'suspect': 21,\n",
       " 'knows': 30,\n",
       " 'flatter': 5,\n",
       " 'reflection': 18,\n",
       " 'has': 243,\n",
       " 'persons': 11,\n",
       " 'chances': 5,\n",
       " 'gainer': 1,\n",
       " 'willing': 13,\n",
       " 'let': 64,\n",
       " 'pass': 30,\n",
       " '--\"': 87,\n",
       " 'hear': 100,\n",
       " 'behaved': 11,\n",
       " 'charmingly': 4,\n",
       " 'Every': 37,\n",
       " 'punctual': 1,\n",
       " 'looks': 29,\n",
       " 'tear': 4,\n",
       " 'face': 32,\n",
       " 'seen': 73,\n",
       " 'apart': 3,\n",
       " 'Dear': 23,\n",
       " 'bears': 2,\n",
       " 'sorry': 61,\n",
       " 'lose': 19,\n",
       " '_will_': 3,\n",
       " 'miss': 7,\n",
       " 'thinks': 23,\n",
       " 'turned': 29,\n",
       " 'divided': 4,\n",
       " 'tears': 9,\n",
       " 'smiles': 14,\n",
       " 'should': 366,\n",
       " 'acceptable': 8,\n",
       " 'important': 20,\n",
       " 'secure': 9,\n",
       " 'provision': 3,\n",
       " 'therefore': 62,\n",
       " 'allow': 47,\n",
       " 'pain': 33,\n",
       " 'happily': 15,\n",
       " 'forgotten': 19,\n",
       " 'matter': 32,\n",
       " 'considerable': 17,\n",
       " 'four': 29,\n",
       " 'proved': 16,\n",
       " 'marry': 63,\n",
       " 'shook': 8,\n",
       " 'fondly': 4,\n",
       " 'replied': 79,\n",
       " 'matches': 6,\n",
       " 'foretell': 2,\n",
       " 'whatever': 16,\n",
       " 'Pray': 15,\n",
       " 'none': 27,\n",
       " 'greatest': 29,\n",
       " 'amusement': 16,\n",
       " 'success': 10,\n",
       " 'widower': 2,\n",
       " 'perfectly': 65,\n",
       " 'constantly': 8,\n",
       " 'occupied': 16,\n",
       " 'either': 61,\n",
       " 'friends': 82,\n",
       " 'wherever': 7,\n",
       " 'need': 42,\n",
       " 'spend': 18,\n",
       " 'single': 19,\n",
       " 'year': 28,\n",
       " 'alone': 27,\n",
       " 'Some': 14,\n",
       " 'deathbed': 1,\n",
       " 'others': 60,\n",
       " 'son': 46,\n",
       " 'uncle': 21,\n",
       " 'letting': 3,\n",
       " 'solemn': 5,\n",
       " 'nonsense': 15,\n",
       " 'subject': 97,\n",
       " 'believed': 46,\n",
       " 'Ever': 4,\n",
       " 'since': 63,\n",
       " 'met': 38,\n",
       " 'Broadway': 1,\n",
       " 'Lane': 6,\n",
       " 'began': 64,\n",
       " 'drizzle': 1,\n",
       " 'darted': 3,\n",
       " 'gallantry': 12,\n",
       " 'borrowed': 2,\n",
       " 'umbrellas': 2,\n",
       " 'Farmer': 1,\n",
       " 'Mitchell': 1,\n",
       " 'planned': 2,\n",
       " 'blessed': 6,\n",
       " 'instance': 9,\n",
       " 'leave': 54,\n",
       " 'making': 56,\n",
       " 'understand': 68,\n",
       " ',\\'\"': 1,\n",
       " 'Success': 1,\n",
       " 'supposes': 1,\n",
       " 'endeavour': 14,\n",
       " 'Your': 27,\n",
       " 'properly': 10,\n",
       " 'delicately': 1,\n",
       " 'endeavouring': 3,\n",
       " 'bring': 38,\n",
       " 'worthy': 18,\n",
       " 'employment': 10,\n",
       " 'young': 190,\n",
       " 'lady': 72,\n",
       " 'imagine': 53,\n",
       " 'planning': 3,\n",
       " 'saying': 51,\n",
       " 'yourself': 56,\n",
       " 'idle': 4,\n",
       " \",'\": 32,\n",
       " 'why': 33,\n",
       " 'talk': 60,\n",
       " 'Where': 16,\n",
       " 'merit': 14,\n",
       " 'proud': 8,\n",
       " 'guess': 25,\n",
       " '_that_': 12,\n",
       " 'can': 270,\n",
       " 'known': 60,\n",
       " 'triumph': 6,\n",
       " 'cleverer': 3,\n",
       " 'depend': 16,\n",
       " 'merely': 29,\n",
       " 'luck': 11,\n",
       " 'There': 129,\n",
       " 'talent': 9,\n",
       " 'word': 94,\n",
       " 'quarrel': 11,\n",
       " 'claim': 12,\n",
       " 'drawn': 15,\n",
       " 'pictures': 2,\n",
       " 'something': 105,\n",
       " 'nothing': 237,\n",
       " 'If': 110,\n",
       " 'visits': 14,\n",
       " 'given': 77,\n",
       " 'encouragements': 1,\n",
       " 'smoothed': 2,\n",
       " 'matters': 10,\n",
       " 'enough': 129,\n",
       " 'comprehend': 15,\n",
       " 'straightforward': 3,\n",
       " 'open': 40,\n",
       " 'hearted': 13,\n",
       " 'unaffected': 4,\n",
       " 'safely': 19,\n",
       " 'manage': 5,\n",
       " 'likely': 46,\n",
       " 'harm': 13,\n",
       " 'interference': 7,\n",
       " 'rejoined': 2,\n",
       " 'understanding': 26,\n",
       " 'pray': 11,\n",
       " 'silly': 12,\n",
       " 'break': 12,\n",
       " 'circle': 18,\n",
       " 'grievously': 1,\n",
       " 'Only': 14,\n",
       " 'Elton': 385,\n",
       " ',--': 38,\n",
       " 'look': 116,\n",
       " 'whole': 76,\n",
       " 'fitted': 1,\n",
       " 'comfortably': 11,\n",
       " 'shame': 9,\n",
       " 'longer': 59,\n",
       " 'joining': 2,\n",
       " 'hands': 23,\n",
       " 'same': 102,\n",
       " 'service': 22,\n",
       " 'shew': 28,\n",
       " 'attention': 59,\n",
       " 'ask': 43,\n",
       " 'dare': 59,\n",
       " 'With': 30,\n",
       " 'laughing': 17,\n",
       " 'Invite': 2,\n",
       " 'fish': 2,\n",
       " 'chicken': 2,\n",
       " 'chuse': 23,\n",
       " 'Depend': 10,\n",
       " 'six': 10,\n",
       " 'care': 51,\n",
       " 'II': 4,\n",
       " 'native': 5,\n",
       " 'born': 6,\n",
       " 'respectable': 20,\n",
       " 'generations': 2,\n",
       " 'rising': 6,\n",
       " 'gentility': 6,\n",
       " 'property': 6,\n",
       " 'received': 36,\n",
       " 'education': 16,\n",
       " 'succeeding': 5,\n",
       " 'small': 30,\n",
       " 'become': 12,\n",
       " 'indisposed': 3,\n",
       " 'homely': 1,\n",
       " 'pursuits': 2,\n",
       " 'brothers': 4,\n",
       " 'engaged': 37,\n",
       " 'satisfied': 51,\n",
       " 'active': 7,\n",
       " 'social': 6,\n",
       " 'entering': 8,\n",
       " 'militia': 2,\n",
       " 'county': 2,\n",
       " 'embodied': 1,\n",
       " 'Captain': 3,\n",
       " 'general': 64,\n",
       " 'favourite': 23,\n",
       " 'military': 1,\n",
       " 'introduced': 8,\n",
       " 'Churchill': 223,\n",
       " 'Yorkshire': 8,\n",
       " 'fell': 10,\n",
       " 'love': 117,\n",
       " 'surprized': 32,\n",
       " 'except': 31,\n",
       " 'full': 44,\n",
       " 'pride': 18,\n",
       " 'importance': 12,\n",
       " 'connexion': 20,\n",
       " 'offend': 3,\n",
       " 'command': 21,\n",
       " 'bore': 7,\n",
       " 'proportion': 4,\n",
       " 'estate': 4,\n",
       " 'dissuaded': 1,\n",
       " 'took': 47,\n",
       " 'infinite': 3,\n",
       " 'mortification': 11,\n",
       " 'threw': 2,\n",
       " 'due': 23,\n",
       " 'decorum': 2,\n",
       " 'unsuitable': 3,\n",
       " 'produce': 10,\n",
       " 'ought': 94,\n",
       " 'whose': 39,\n",
       " 'warm': 30,\n",
       " 'sweet': 22,\n",
       " 'return': 56,\n",
       " 'goodness': 7,\n",
       " 'spirit': 27,\n",
       " 'resolution': 31,\n",
       " 'pursue': 1,\n",
       " 'refrain': 5,\n",
       " 'unreasonable': 9,\n",
       " 'anger': 7,\n",
       " 'missing': 3,\n",
       " 'luxuries': 1,\n",
       " 'former': 13,\n",
       " 'income': 10,\n",
       " 'still': 109,\n",
       " 'comparison': 11,\n",
       " 'Enscombe': 36,\n",
       " 'cease': 7,\n",
       " 'once': 82,\n",
       " ...}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = {}\n",
    "\n",
    "for sent in gutenberg.sents('austen-emma.txt'):\n",
    "    for word in sent:\n",
    "        if word in count:\n",
    "            count[word] += 1\n",
    "        else:\n",
    "            count[word] = 1\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versión mejorada con defaultdicts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "count = defaultdict(int)\n",
    "\n",
    "for sent in gutenberg.sents('austen-emma.txt'):\n",
    "    for word in sent:\n",
    "        count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mejor aun: usar FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = gutenberg.sents('austen-emma.txt')\n",
    "\n",
    "freqs = nltk.FreqDist()\n",
    "\n",
    "for sent in sents:\n",
    "    freqs += nltk.FreqDist(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 11454),\n",
       " ('.', 6928),\n",
       " ('to', 5183),\n",
       " ('the', 4844),\n",
       " ('and', 4672),\n",
       " ('of', 4279),\n",
       " ('I', 3178),\n",
       " ('a', 3004),\n",
       " ('was', 2385),\n",
       " ('her', 2381)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 palabras más frecuentes: [(',', 11454), ('.', 6928), ('to', 5183), ('the', 4844), ('and', 4672), ('of', 4279), ('I', 3178), ('a', 3004), ('was', 2385), ('her', 2381)]\n",
      "Vocabulario: 7806\n",
      "Tokens: 192484\n"
     ]
    }
   ],
   "source": [
    "print('10 palabras más frecuentes:', sorted(count.items(), key=lambda x: -x[1])[:10])\n",
    "print('Vocabulario:', len(count))\n",
    "print('Tokens:', sum(count.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versión usando clase Counter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "count = Counter()\n",
    "\n",
    "for sent in gutenberg.sents('austen-emma.txt'):\n",
    "    count.update(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 palabras más frecuentes: [(',', 11454), ('.', 6928), ('to', 5183), ('the', 4844), ('and', 4672), ('of', 4279), ('I', 3178), ('a', 3004), ('was', 2385), ('her', 2381)]\n",
      "Vocabulario: 7806\n",
      "Tokens: 192484\n"
     ]
    }
   ],
   "source": [
    "print('10 palabras más frecuentes:', count.most_common()[:10])\n",
    "print('Vocabulario:', len(count))\n",
    "print('Tokens:', sum(count.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus de Texto Plano\n",
    "\n",
    "- http://www.nltk.org/api/nltk.corpus.reader.html#nltk.corpus.reader.plaintext.PlaintextCorpusReader\n",
    "- http://www.nltk.org/book/ch02.html\n",
    "\n",
    "Primero crear archivo example.txt: \"Estimados Sr. y sra. Gómez. Se los cita por el art. 32 de la ley 21.234.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class PlaintextCorpusReader in module nltk.corpus.reader.plaintext:\n",
      "\n",
      "class PlaintextCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      " |  Reader for corpora that consist of plaintext documents.  Paragraphs\n",
      " |  are assumed to be split using blank lines.  Sentences and words can\n",
      " |  be tokenized using the default tokenizers, or by custom tokenizers\n",
      " |  specificed as parameters to the constructor.\n",
      " |  \n",
      " |  This corpus reader can be customized (e.g., to skip preface\n",
      " |  sections of specific document formats) by creating a subclass and\n",
      " |  overriding the ``CorpusView`` class variable.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      PlaintextCorpusReader\n",
      " |      nltk.corpus.reader.api.CorpusReader\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, root, fileids, word_tokenizer=WordPunctTokenizer(pattern='\\\\w+|[^\\\\w\\\\s]+', gaps=False, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), sent_tokenizer=<nltk.tokenize.punkt.PunktSentenceTokenizer object at 0x7f1602246e10>, para_block_reader=<function read_blankline_block at 0x7f160225dc80>, encoding='utf8')\n",
      " |      Construct a new plaintext corpus reader for a set of documents\n",
      " |      located at the given root directory.  Example usage:\n",
      " |      \n",
      " |          >>> root = '/usr/local/share/nltk_data/corpora/webtext/'\n",
      " |          >>> reader = PlaintextCorpusReader(root, '.*\\.txt') # doctest: +SKIP\n",
      " |      \n",
      " |      :param root: The root directory for this corpus.\n",
      " |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      " |      :param word_tokenizer: Tokenizer for breaking sentences or\n",
      " |          paragraphs into words.\n",
      " |      :param sent_tokenizer: Tokenizer for breaking paragraphs\n",
      " |          into words.\n",
      " |      :param para_block_reader: The block reader used to divide the\n",
      " |          corpus into paragraph blocks.\n",
      " |  \n",
      " |  paras(self, fileids=None)\n",
      " |      :return: the given file(s) as a list of\n",
      " |          paragraphs, each encoded as a list of sentences, which are\n",
      " |          in turn encoded as lists of word strings.\n",
      " |      :rtype: list(list(list(str)))\n",
      " |  \n",
      " |  raw(self, fileids=None)\n",
      " |      :return: the given file(s) as a single string.\n",
      " |      :rtype: str\n",
      " |  \n",
      " |  sents(self, fileids=None)\n",
      " |      :return: the given file(s) as a list of\n",
      " |          sentences or utterances, each encoded as a list of word\n",
      " |          strings.\n",
      " |      :rtype: list(list(str))\n",
      " |  \n",
      " |  words(self, fileids=None)\n",
      " |      :return: the given file(s) as a list of words\n",
      " |          and punctuation symbols.\n",
      " |      :rtype: list(str)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  CorpusView = <class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      " |      A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      " |      it can be accessed by index, iterated over, etc.  However, the\n",
      " |      tokens are only constructed as-needed -- the entire corpus is\n",
      " |      never stored in memory at once.\n",
      " |      \n",
      " |      The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      " |      a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      " |      and a block reader.  A \"block reader\" is a function that reads\n",
      " |      zero or more tokens from a stream, and returns them as a list.  A\n",
      " |      very simple example of a block reader is:\n",
      " |      \n",
      " |          >>> def simple_block_reader(stream):\n",
      " |          ...     return stream.readline().split()\n",
      " |      \n",
      " |      This simple block reader reads a single line at a time, and\n",
      " |      returns a single token (consisting of a string) for each\n",
      " |      whitespace-separated substring on the line.\n",
      " |      \n",
      " |      When deciding how to define the block reader for a given\n",
      " |      corpus, careful consideration should be given to the size of\n",
      " |      blocks handled by the block reader.  Smaller block sizes will\n",
      " |      increase the memory requirements of the corpus view's internal\n",
      " |      data structures (by 2 integers per block).  On the other hand,\n",
      " |      larger block sizes may decrease performance for random access to\n",
      " |      the corpus.  (But note that larger block sizes will *not*\n",
      " |      decrease performance for iteration.)\n",
      " |      \n",
      " |      Internally, ``CorpusView`` maintains a partial mapping from token\n",
      " |      index to file position, with one entry per block.  When a token\n",
      " |      with a given index *i* is requested, the ``CorpusView`` constructs\n",
      " |      it as follows:\n",
      " |      \n",
      " |        1. First, it searches the toknum/filepos mapping for the token\n",
      " |           index closest to (but less than or equal to) *i*.\n",
      " |      \n",
      " |        2. Then, starting at the file position corresponding to that\n",
      " |           index, it reads one block at a time using the block reader\n",
      " |           until it reaches the requested token.\n",
      " |      \n",
      " |      The toknum/filepos mapping is created lazily: it is initially\n",
      " |      empty, but every time a new block is read, the block's\n",
      " |      initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      " |      map has one entry per block.)\n",
      " |      \n",
      " |      In order to increase efficiency for random access patterns that\n",
      " |      have high degrees of locality, the corpus view may cache one or\n",
      " |      more blocks.\n",
      " |      \n",
      " |      :note: Each ``CorpusView`` object internally maintains an open file\n",
      " |          object for its underlying corpus file.  This file should be\n",
      " |          automatically closed when the ``CorpusView`` is garbage collected,\n",
      " |          but if you wish to close it manually, use the ``close()``\n",
      " |          method.  If you access a ``CorpusView``'s items after it has been\n",
      " |          closed, the file object will be automatically re-opened.\n",
      " |      \n",
      " |      :warning: If the contents of the file are modified during the\n",
      " |          lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      " |          is undefined.\n",
      " |      \n",
      " |      :warning: If a unicode encoding is specified when constructing a\n",
      " |          ``CorpusView``, then the block reader may only call\n",
      " |          ``stream.seek()`` with offsets that have been returned by\n",
      " |          ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      " |          relative offsets, or with offsets based on string lengths, may\n",
      " |          lead to incorrect behavior.\n",
      " |      \n",
      " |      :ivar _block_reader: The function used to read\n",
      " |          a single block from the underlying file stream.\n",
      " |      :ivar _toknum: A list containing the token index of each block\n",
      " |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      " |          token index of the first token in block ``i``.  Together\n",
      " |          with ``_filepos``, this forms a partial mapping between token\n",
      " |          indices and file positions.\n",
      " |      :ivar _filepos: A list containing the file position of each block\n",
      " |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      " |          file position of the first character in block ``i``.  Together\n",
      " |          with ``_toknum``, this forms a partial mapping between token\n",
      " |          indices and file positions.\n",
      " |      :ivar _stream: The stream used to access the underlying corpus file.\n",
      " |      :ivar _len: The total number of tokens in the corpus, if known;\n",
      " |          or None, if the number of tokens is not yet known.\n",
      " |      :ivar _eofpos: The character position of the last character in the\n",
      " |          file.  This is calculated when the corpus view is initialized,\n",
      " |          and is used to decide when the end of file has been reached.\n",
      " |      :ivar _cache: A cache of the most recently read block.  It\n",
      " |         is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      " |         start_toknum is the token index of the first token in the block;\n",
      " |         end_toknum is the token index of the first token not in the\n",
      " |         block; and tokens is a list of the tokens in the block.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __unicode__ = __str__(self, /)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  abspath(self, fileid)\n",
      " |      Return the absolute path for the given file.\n",
      " |      \n",
      " |      :type fileid: str\n",
      " |      :param fileid: The file identifier for the file whose path\n",
      " |          should be returned.\n",
      " |      :rtype: PathPointer\n",
      " |  \n",
      " |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      " |      Return a list of the absolute paths for all fileids in this corpus;\n",
      " |      or for the given list of fileids, if specified.\n",
      " |      \n",
      " |      :type fileids: None or str or list\n",
      " |      :param fileids: Specifies the set of fileids for which paths should\n",
      " |          be returned.  Can be None, for all fileids; a list of\n",
      " |          file identifiers, for a specified set of fileids; or a single\n",
      " |          file identifier, for a single file.  Note that the return\n",
      " |          value is always a list of paths, even if ``fileids`` is a\n",
      " |          single file identifier.\n",
      " |      \n",
      " |      :param include_encoding: If true, then return a list of\n",
      " |          ``(path_pointer, encoding)`` tuples.\n",
      " |      \n",
      " |      :rtype: list(PathPointer)\n",
      " |  \n",
      " |  citation(self)\n",
      " |      Return the contents of the corpus citation.bib file, if it exists.\n",
      " |  \n",
      " |  encoding(self, file)\n",
      " |      Return the unicode encoding for the given corpus file, if known.\n",
      " |      If the encoding is unknown, or if the given file should be\n",
      " |      processed using byte strings (str), then return None.\n",
      " |  \n",
      " |  ensure_loaded(self)\n",
      " |      Load this corpus (if it has not already been loaded).  This is\n",
      " |      used by LazyCorpusLoader as a simple method that can be used to\n",
      " |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      " |      do help(some_corpus).\n",
      " |  \n",
      " |  fileids(self)\n",
      " |      Return a list of file identifiers for the fileids that make up\n",
      " |      this corpus.\n",
      " |  \n",
      " |  license(self)\n",
      " |      Return the contents of the corpus LICENSE file, if it exists.\n",
      " |  \n",
      " |  open(self, file)\n",
      " |      Return an open stream that can be used to read the given file.\n",
      " |      If the file's encoding is not None, then the stream will\n",
      " |      automatically decode the file's contents into unicode.\n",
      " |      \n",
      " |      :param file: The file identifier of the file to read.\n",
      " |  \n",
      " |  readme(self)\n",
      " |      Return the contents of the corpus README file, if it exists.\n",
      " |  \n",
      " |  unicode_repr = __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  root\n",
      " |      The directory where this corpus is stored.\n",
      " |      \n",
      " |      :type: PathPointer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader\n",
    "\n",
    "help(PlaintextCorpusReader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = PlaintextCorpusReader('.', 'example.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hola',\n",
       "  'soy',\n",
       "  'el',\n",
       "  'sapo',\n",
       "  'pepe',\n",
       "  'soy',\n",
       "  'pepe',\n",
       "  'y',\n",
       "  'me',\n",
       "  'gusta',\n",
       "  'comer',\n",
       "  'moscas',\n",
       "  'soy',\n",
       "  'pepe',\n",
       "  'pero',\n",
       "  'no',\n",
       "  'me',\n",
       "  'gusta',\n",
       "  'comer',\n",
       "  'sapos',\n",
       "  'soy',\n",
       "  'un',\n",
       "  'sapo',\n",
       "  'manco',\n",
       "  'y',\n",
       "  'me',\n",
       "  'quedo',\n",
       "  'dormido']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(corpus.sents())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenización\n",
    "\n",
    "- http://www.nltk.org/api/nltk.tokenize.html#nltk.tokenize.regexp.RegexpTokenizer\n",
    "- http://www.nltk.org/book/ch03.html#regular-expressions-for-tokenizing-text\n",
    "\n",
    "De la documentación de NLTK obtenemos una expresión regular para tokenizar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'''(?x)    # set flag to allow verbose regexps\n",
    "     (?:[A-Z]\\.)+        # abbreviations, e.g. U.S.A.\n",
    "   | \\w+(?:-\\w+)*        # words with optional internal hyphens\n",
    "   | \\$?\\d+(?:\\.\\d+)?%?  # currency and percentages, e.g. $12.40, 82%\n",
    "   | \\.\\.\\.            # ellipsis\n",
    "   | [][.,;\"'?():-_`]  # these are separate tokens; includes ], [\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo probamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hola',\n",
       "  'soy',\n",
       "  'el',\n",
       "  'sapo',\n",
       "  'pepe',\n",
       "  'soy',\n",
       "  'pepe',\n",
       "  'y',\n",
       "  'me',\n",
       "  'gusta',\n",
       "  'comer',\n",
       "  'moscas',\n",
       "  'soy',\n",
       "  'pepe',\n",
       "  'pero',\n",
       "  'no',\n",
       "  'me',\n",
       "  'gusta',\n",
       "  'comer',\n",
       "  'sapos',\n",
       "  'soy',\n",
       "  'un',\n",
       "  'sapo',\n",
       "  'manco',\n",
       "  'y',\n",
       "  'me',\n",
       "  'quedo',\n",
       "  'dormido']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(pattern)\n",
    "\n",
    "corpus = PlaintextCorpusReader('.', 'example.txt', word_tokenizer=tokenizer)\n",
    "list(corpus.sents())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que tokeniza mal todas las abreviaciones y el número \"21.234\".\n",
    "Mejoramos la expresión regular y probamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hola',\n",
       "  'soy',\n",
       "  'el',\n",
       "  'sapo',\n",
       "  'pepe',\n",
       "  'soy',\n",
       "  'pepe',\n",
       "  'y',\n",
       "  'me',\n",
       "  'gusta',\n",
       "  'comer',\n",
       "  'moscas',\n",
       "  'soy',\n",
       "  'pepe',\n",
       "  'pero',\n",
       "  'no',\n",
       "  'me',\n",
       "  'gusta',\n",
       "  'comer',\n",
       "  'sapos',\n",
       "  'soy',\n",
       "  'un',\n",
       "  'sapo',\n",
       "  'manco',\n",
       "  'y',\n",
       "  'me',\n",
       "  'quedo',\n",
       "  'dormido']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r'''(?x)    # set flag to allow verbose regexps\n",
    "   (?:\\d{1,3}(?:\\.\\d{3})+)  # numbers with '.' in the middle\n",
    "   | (?:[Ss]r\\.|[Ss]ra\\.|art\\.)  # common spanish abbreviations\n",
    "   | (?:[A-Z]\\.)+        # abbreviations, e.g. U.S.A.\n",
    "   | \\w+(?:-\\w+)*        # words with optional internal hyphens\n",
    "   | \\$?\\d+(?:\\.\\d+)?%?  # currency and percentages, e.g. $12.40, 82%\n",
    "   | \\.\\.\\.            # ellipsis\n",
    "   | [][.,;\"'?():-_`]  # these are separate tokens; includes ], [\n",
    "'''\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(pattern)\n",
    "\n",
    "corpus = PlaintextCorpusReader('.', 'example.txt', word_tokenizer=tokenizer)\n",
    "list(corpus.sents())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tokeniza bien!!\n",
    "\n",
    "(La segmentación en oraciones sigue estando mal, pero resolver eso queda fuera de esta clase.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
